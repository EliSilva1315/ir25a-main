{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "941741204a003f44",
   "metadata": {},
   "source": [
    "# Ejercicio 4: Modelo Probabilístico\n",
    "\n",
    "## Objetivo de la práctica\n",
    "- Comprender los componentes del modelo vectorial mediante cálculos manuales y observación directa.\n",
    "- Aplicar el modelo de espacio vectorial con TF-IDF para recuperar documentos relevantes.\n",
    "- Comparar la recuperación con BM25 frente a TF-IDF.\n",
    "- Analizar visualmente las diferencias entre los modelos.\n",
    "- Evaluar si los rankings generados son consistentes con lo que considerarías documentos relevantes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bafe7a6a4ef9e5",
   "metadata": {},
   "source": [
    "## Parte 0: Carga del Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad08bb8bd43ae327",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T14:16:07.323562Z",
     "start_time": "2025-05-21T14:16:05.364309Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "newsgroups = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\n",
    "newsgroupsdocs = newsgroups.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "88a79deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "#tipo de newsgroupsdocs\n",
    "print(type(newsgroupsdocs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "48ffd979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "I am sure some bashers of Pens fans are pretty confused about the lack\n",
      "of any kind of posts about the recent Pens massacre of the Devils. Actually,\n",
      "I am  bit puzzled too and a bit relieved. However, I am going to put an end\n",
      "to non-PIttsburghers' relief with a bit of praise for the Pens. Man, they\n",
      "are killing those Devils worse than I thought. Jagr just showed you why\n",
      "he is much better than his regular season stats. He is also a lot\n",
      "fo fun to watch in the playoffs. Bowman should let JAgr have a lot of\n",
      "fun in the next couple of games since the Pens are going to beat the pulp out of Jersey anyway. I was very disappointed not to see the Islanders lose the final\n",
      "regular season game.          PENS RULE!!!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#ver un documento\n",
    "print(newsgroupsdocs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a3cb3370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150808\n"
     ]
    }
   ],
   "source": [
    "#peso de newsgroupsdocs\n",
    "print(newsgroupsdocs.__sizeof__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aba8255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18846, 134410)\n",
      "(18846, 134410)\n"
     ]
    }
   ],
   "source": [
    "#vectorizando newsgroupsdocs \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "#tamaño del vector\n",
    "X = vectorizer.fit_transform(newsgroupsdocs)\n",
    "print(X.shape)\n",
    "corpus_vect=vectorizer.transform(newsgroupsdocs)\n",
    "corpus_vect.toarray()\n",
    "#tamaño del vector\n",
    "print(corpus_vect.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "62ae78c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0.03797469 0.         0.02884581 ... 0.         0.         0.08310875]]\n"
     ]
    }
   ],
   "source": [
    "# query chicken\n",
    "query = [\"some\"]\n",
    "#vectorizando query\n",
    "query_vect = vectorizer.transform(query)\n",
    "#valor de la query\n",
    "print(query_vect.toarray())\n",
    "#similaridad entre query y corpus\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarity = cosine_similarity(query_vect, corpus_vect)\n",
    "#similaridad entre query y corpus\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f8c7f78934f497",
   "metadata": {},
   "source": [
    "## Parte 1: Cálculo de TF, DF, IDF y TF-IDF\n",
    "\n",
    "### Actividad \n",
    "1. Utiliza el corpus cargado.\n",
    "2. Construye la matriz de términos (TF), y calcula la frecuencia de documentos (DF)\n",
    "3. Calcula TF-IDF utilizando sklearn.\n",
    "4. Visualiza los valores en un DataFrame para analizar las diferencias entre los términos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3c6c9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2ebd9f1c1b6c787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       data  descr  filenames  target_names  target\n",
      "0         0      0          0             0       0\n",
      "1         0      0          0             0       0\n",
      "2         0      0          0             0       0\n",
      "3         6      0          0             0       0\n",
      "4         0      0          0             0       0\n",
      "...     ...    ...        ...           ...     ...\n",
      "18841     0      0          0             0       0\n",
      "18842     0      0          0             0       0\n",
      "18843     0      0          0             0       0\n",
      "18844     0      0          0             0       0\n",
      "18845     0      0          0             0       0\n",
      "\n",
      "[18846 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Paso 1: Construcción del vocabulario (limpieza básica de texto)\n",
    "vocabulary = set()\n",
    "for doc in newsgroups:\n",
    "    # Eliminamos caracteres no alfabéticos y convertimos a minúsculas\n",
    "    words = re.findall(r'\\b\\w+\\b', doc.lower())\n",
    "    vocabulary.update(words)\n",
    "\n",
    "vocabulary = list(vocabulary)  # Convertimos el set en lista para mantener el orden\n",
    "\n",
    "# Paso 2: Construcción de la matriz término-documento (frecuencia de término)\n",
    "dict_tf = {}\n",
    "for i, doc in enumerate(newsgroupsdocs):\n",
    "    dict_tfd = {}\n",
    "    words = re.findall(r'\\b\\w+\\b', doc.lower())  # Limpiamos igual que antes\n",
    "    for term in vocabulary:\n",
    "        dict_tfd[term] = words.count(term)\n",
    "    dict_tf[i] = dict_tfd\n",
    "\n",
    "# Paso 3: Crear la matriz término-documento como DataFrame\n",
    "matriz = pd.DataFrame.from_dict(dict_tf, orient='index')  # Documentos como filas\n",
    "print(matriz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb00e2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "764c027a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af3232aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores IDF:\n",
      "data            3.192484\n",
      "descr           9.844056\n",
      "filenames       7.764614\n",
      "target_names    9.844056\n",
      "target          5.056564\n",
      "dtype: float64\n",
      "\n",
      "Matriz TF-IDF:\n",
      "            data  descr  filenames  target_names  target\n",
      "0       0.000000    0.0        0.0           0.0     0.0\n",
      "1       0.000000    0.0        0.0           0.0     0.0\n",
      "2       0.000000    0.0        0.0           0.0     0.0\n",
      "3      19.154905    0.0        0.0           0.0     0.0\n",
      "4       0.000000    0.0        0.0           0.0     0.0\n",
      "...          ...    ...        ...           ...     ...\n",
      "18841   0.000000    0.0        0.0           0.0     0.0\n",
      "18842   0.000000    0.0        0.0           0.0     0.0\n",
      "18843   0.000000    0.0        0.0           0.0     0.0\n",
      "18844   0.000000    0.0        0.0           0.0     0.0\n",
      "18845   0.000000    0.0        0.0           0.0     0.0\n",
      "\n",
      "[18846 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Paso 4: Calcular el IDF para cada término\n",
    "N = len(newsgroupsdocs)\n",
    "df = (matriz > 0).sum(axis=0)  # Número de documentos en los que aparece cada término\n",
    "idf = np.log((N) / (df + 1))  # Suma 1 para evitar división por cero\n",
    "\n",
    "# Paso 5: Calcular la matriz TF-IDF\n",
    "matriz_tfidf = matriz * idf\n",
    "\n",
    "# Mostrar matrices\n",
    "print(\"\\nValores IDF:\")\n",
    "print(idf.head(20))  # Mostrar los primeros 20 términos\n",
    "\n",
    "print(\"\\nMatriz TF-IDF:\")\n",
    "print(matriz_tfidf.iloc[:, :20])  # Mostrar primeras 20 columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "85d91ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Visualización de TF-IDF:\n",
      "            data  target  filenames  descr  target_names\n",
      "0       0.000000     0.0        0.0    0.0           0.0\n",
      "1       0.000000     0.0        0.0    0.0           0.0\n",
      "2       0.000000     0.0        0.0    0.0           0.0\n",
      "3      19.154905     0.0        0.0    0.0           0.0\n",
      "4       0.000000     0.0        0.0    0.0           0.0\n",
      "...          ...     ...        ...    ...           ...\n",
      "18841   0.000000     0.0        0.0    0.0           0.0\n",
      "18842   0.000000     0.0        0.0    0.0           0.0\n",
      "18843   0.000000     0.0        0.0    0.0           0.0\n",
      "18844   0.000000     0.0        0.0    0.0           0.0\n",
      "18845   0.000000     0.0        0.0    0.0           0.0\n",
      "\n",
      "[18846 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Seleccionar los 20 términos más frecuentes (con menor IDF)\n",
    "top_terms = idf.sort_values().head().index  # Los términos más comunes\n",
    "\n",
    "# Crear un DataFrame solo con estos términos para todos los documentos\n",
    "visual_df = matriz_tfidf[top_terms]\n",
    "\n",
    "# Mostrar la tabla\n",
    "print(\"\\nVisualización de TF-IDF:\")\n",
    "print(visual_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64491bce5361e8b3",
   "metadata": {},
   "source": [
    "## Parte 2: Ranking de documentos usando TF-IDF\n",
    "\n",
    "### Actividad \n",
    "\n",
    "1. Dada una consulta, construye el vector de consulta\n",
    "2. Calcula la similitud coseno entre la consulta y cada documento usando los vectores TF-IDF\n",
    "3. Genera un ranking de los documentos ordenados por relevancia.\n",
    "4. Muestra los resultados en una tabla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d082c4a156b9554",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97061325508dc5f2",
   "metadata": {},
   "source": [
    "## Parte 3: Ranking con BM25\n",
    "\n",
    "### Actividad \n",
    "\n",
    "1. Implementa un sistema de recuperación usando el modelo BM25.\n",
    "2. Usa la misma consulta del ejercicio anterior.\n",
    "3. Calcula el score BM25 para cada documento y genera un ranking.\n",
    "4. Compara manualmente con el ranking de TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0dca2bcfa73c5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c71b85e77b4b181",
   "metadata": {},
   "source": [
    "## Parte 4: Comparación visual entre TF-IDF y BM25\n",
    "\n",
    "### Actividad \n",
    "\n",
    "1. Utiliza un gráfico de barras para visualizar los scores obtenidos por cada documento según TF-IDF y BM25.\n",
    "2. Compara los rankings visualmente.\n",
    "3. Identifica: ¿Qué documentos obtienen scores más altos en un modelo que en otro?\n",
    "4. Sugiere: ¿A qué se podría deber esta diferencia?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ad3d9d16c04d35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b97d171655ecfb",
   "metadata": {},
   "source": [
    "## Parte 5: Evaluación con consulta relevante\n",
    "\n",
    "### Actividad \n",
    "\n",
    "1. Elige una consulta y define qué documentos del corpus deberían considerarse relevantes.\n",
    "2. Evalúa Precision@3 o MAP para los rankings generados con TF-IDF y BM25.\n",
    "3. Responde: ¿Cuál modelo da mejores resultados respecto a tu criterio de relevancia?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5de59378900ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

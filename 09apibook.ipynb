{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5888edd",
   "metadata": {},
   "source": [
    "Consulta a un libro con retrieval augmented generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b055381",
   "metadata": {},
   "source": [
    "CARGA DE TEXTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caeee2ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page</th>\n",
       "      <th>raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>b'Online edition (c)\\n2009 Cambridge UP\\nAn\\nI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>b'Online edition (c)\\n2009 Cambridge UP\\n'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>b'Online edition (c)\\n2009 Cambridge UP\\nAn\\nI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>b'Online edition (c)\\n2009 Cambridge UP\\nDRAFT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>b'Online edition (c)\\n2009 Cambridge UP\\nDRAFT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>577</td>\n",
       "      <td>b'Online edition (c)\\n2009 Cambridge UP\\n540\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>578</td>\n",
       "      <td>b'Online edition (c)\\n2009 Cambridge UP\\nIndex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>579</td>\n",
       "      <td>b'Online edition (c)\\n2009 Cambridge UP\\n542\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>580</td>\n",
       "      <td>b'Online edition (c)\\n2009 Cambridge UP\\nIndex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>581</td>\n",
       "      <td>b'Online edition (c)\\n2009 Cambridge UP\\n544\\n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>581 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     page                                                raw\n",
       "0       1  b'Online edition (c)\\n2009 Cambridge UP\\nAn\\nI...\n",
       "1       2         b'Online edition (c)\\n2009 Cambridge UP\\n'\n",
       "2       3  b'Online edition (c)\\n2009 Cambridge UP\\nAn\\nI...\n",
       "3       4  b'Online edition (c)\\n2009 Cambridge UP\\nDRAFT...\n",
       "4       5  b'Online edition (c)\\n2009 Cambridge UP\\nDRAFT...\n",
       "..    ...                                                ...\n",
       "576   577  b'Online edition (c)\\n2009 Cambridge UP\\n540\\n...\n",
       "577   578  b'Online edition (c)\\n2009 Cambridge UP\\nIndex...\n",
       "578   579  b'Online edition (c)\\n2009 Cambridge UP\\n542\\n...\n",
       "579   580  b'Online edition (c)\\n2009 Cambridge UP\\nIndex...\n",
       "580   581  b'Online edition (c)\\n2009 Cambridge UP\\n544\\n...\n",
       "\n",
       "[581 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pymupdf\n",
    "import pymupdf as fitz\n",
    "\n",
    "# Ruta al archivo PDF\n",
    "path = \"C:\\\\Users\\\\ELI\\\\Downloads\\\\irbookonlinereading.pdf\"\n",
    "doc = pymupdf.open(path)\n",
    "data=[]\n",
    "for i, page in enumerate(doc):\n",
    "    text = page.get_text().encode('utf-8')\n",
    "    if text.strip():\n",
    "        data.append({\n",
    "            \"page\": i + 1,\n",
    "            \"raw\": str(text).strip()\n",
    "        })\n",
    "# Convertir a DataFrame\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6ad9d0",
   "metadata": {},
   "source": [
    "TABLA DE CONTENIDOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96b5f436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡El PDF tiene 256 elementos en la tabla de contenidos!\n",
      "\n",
      "Primeras 10 entradas:\n",
      "Nivel 1: List of Tables (Página 15)\n",
      "Nivel 1: List of Figures (Página 19)\n",
      "Nivel 1: Table of Notation (Página 27)\n",
      "Nivel 1: Preface (Página 31)\n",
      "Nivel 1: Boolean retrieval (Página 38)\n",
      "  Nivel 2: An example information retrieval problem (Página 40)\n",
      "  Nivel 2: A first take at building an inverted index (Página 43)\n",
      "  Nivel 2: Processing Boolean queries (Página 47)\n",
      "  Nivel 2: The extended Boolean model versus ranked retrieval (Página 51)\n",
      "  Nivel 2: References and further reading (Página 54)\n",
      "Nivel 1: The term vocabulary and postings lists (Página 56)\n",
      "  Nivel 2: Document delineation and character sequence decoding (Página 56)\n",
      "    Nivel 3: Obtaining the character sequence in a document (Página 56)\n",
      "    Nivel 3: Choosing a document unit (Página 57)\n",
      "  Nivel 2: Determining the vocabulary of terms (Página 59)\n",
      "    Nivel 3: Tokenization (Página 59)\n",
      "    Nivel 3: Dropping common terms: stop words (Página 64)\n",
      "    Nivel 3: Normalization (equivalence classing of terms) (Página 65)\n",
      "    Nivel 3: Stemming and lemmatization (Página 69)\n",
      "  Nivel 2: Faster postings list intersection via skip pointers (Página 73)\n",
      "  Nivel 2: Positional postings and phrase queries (Página 76)\n",
      "    Nivel 3: Biword indexes (Página 76)\n",
      "    Nivel 3: Positional indexes (Página 78)\n",
      "    Nivel 3: Combination schemes (Página 80)\n",
      "  Nivel 2: References and further reading (Página 82)\n",
      "Nivel 1: Dictionaries and tolerant retrieval (Página 86)\n",
      "  Nivel 2: Search structures for dictionaries (Página 86)\n",
      "  Nivel 2: Wildcard queries (Página 88)\n",
      "    Nivel 3: General wildcard queries (Página 90)\n",
      "    Nivel 3: k-gram indexes for wildcard queries (Página 91)\n",
      "  Nivel 2: Spelling correction (Página 93)\n",
      "    Nivel 3: Implementing spelling correction (Página 94)\n",
      "    Nivel 3: Forms of spelling correction (Página 94)\n",
      "    Nivel 3: Edit distance (Página 95)\n",
      "    Nivel 3: k-gram indexes for spelling correction (Página 97)\n",
      "    Nivel 3: Context sensitive spelling correction (Página 99)\n",
      "  Nivel 2: Phonetic correction (Página 100)\n",
      "  Nivel 2: References and further reading (Página 102)\n",
      "Nivel 1: Index construction (Página 104)\n",
      "  Nivel 2: Hardware basics (Página 105)\n",
      "  Nivel 2: Blocked sort-based indexing (Página 106)\n",
      "  Nivel 2: Single-pass in-memory indexing (Página 110)\n",
      "  Nivel 2: Distributed indexing (Página 111)\n",
      "  Nivel 2: Dynamic indexing (Página 115)\n",
      "  Nivel 2: Other types of indexes (Página 117)\n",
      "  Nivel 2: References and further reading (Página 120)\n",
      "Nivel 1: Index compression (Página 122)\n",
      "  Nivel 2: Statistical properties of terms in information retrieval (Página 123)\n",
      "    Nivel 3: Heaps' law: Estimating the number of terms (Página 125)\n",
      "    Nivel 3: Zipf's law: Modeling the distribution of terms (Página 126)\n",
      "  Nivel 2: Dictionary compression (Página 127)\n",
      "    Nivel 3: Dictionary as a string (Página 128)\n",
      "    Nivel 3: Blocked storage (Página 129)\n",
      "  Nivel 2: Postings file compression (Página 132)\n",
      "    Nivel 3: Variable byte codes (Página 133)\n",
      "    Nivel 3: Gamma codes (Página 135)\n",
      "  Nivel 2: References and further reading (Página 142)\n",
      "Nivel 1: Scoring, term weighting and the vector space model (Página 146)\n",
      "  Nivel 2: Parametric and zone indexes (Página 147)\n",
      "    Nivel 3: Weighted zone scoring (Página 149)\n",
      "    Nivel 3: Learning weights (Página 150)\n",
      "    Nivel 3: The optimal weight g (Página 152)\n",
      "  Nivel 2: Term frequency and weighting (Página 154)\n",
      "    Nivel 3: Inverse document frequency (Página 154)\n",
      "    Nivel 3: Tf-idf weighting (Página 155)\n",
      "  Nivel 2: The vector space model for scoring (Página 157)\n",
      "    Nivel 3: Dot products (Página 157)\n",
      "    Nivel 3: Queries as vectors (Página 160)\n",
      "    Nivel 3: Computing vector scores (Página 161)\n",
      "  Nivel 2: Variant tf-idf functions (Página 163)\n",
      "    Nivel 3: Sublinear tf scaling (Página 163)\n",
      "    Nivel 3: Maximum tf normalization (Página 164)\n",
      "    Nivel 3: Document and query weighting schemes (Página 165)\n",
      "    Nivel 3: Pivoted normalized document length (Página 166)\n",
      "  Nivel 2: References and further reading (Página 170)\n",
      "Nivel 1: Computing scores in a complete search system (Página 172)\n",
      "  Nivel 2: Efficient scoring and ranking (Página 172)\n",
      "    Nivel 3: Inexact top K document retrieval (Página 174)\n",
      "    Nivel 3: Index elimination (Página 174)\n",
      "    Nivel 3: Champion lists (Página 175)\n",
      "    Nivel 3: Static quality scores and ordering (Página 175)\n",
      "    Nivel 3: Impact ordering (Página 177)\n",
      "    Nivel 3: Cluster pruning (Página 178)\n",
      "  Nivel 2: Components of an information retrieval system (Página 180)\n",
      "    Nivel 3: Tiered indexes (Página 180)\n",
      "    Nivel 3: Query-term proximity (Página 181)\n",
      "    Nivel 3: Designing parsing and scoring functions (Página 182)\n",
      "    Nivel 3: Putting it all together (Página 183)\n",
      "  Nivel 2: Vector space scoring and query operator interaction (Página 184)\n",
      "  Nivel 2: References and further reading (Página 186)\n",
      "Nivel 1: Evaluation in information retrieval (Página 188)\n",
      "  Nivel 2: Information retrieval system evaluation (Página 189)\n",
      "  Nivel 2: Standard test collections (Página 190)\n",
      "  Nivel 2: Evaluation of unranked retrieval sets (Página 191)\n",
      "  Nivel 2: Evaluation of ranked retrieval results (Página 195)\n",
      "  Nivel 2: Assessing relevance (Página 201)\n",
      "    Nivel 3: Critiques and justifications of the concept of relevance (Página 203)\n",
      "  Nivel 2: A broader perspective: System quality and user utility (Página 205)\n",
      "    Nivel 3: System issues (Página 205)\n",
      "    Nivel 3: User utility (Página 206)\n"
     ]
    }
   ],
   "source": [
    "# Verificar si el PDF tiene tabla de contenidos (TOC)\n",
    "toc = doc.get_toc()\n",
    "\n",
    "if toc:\n",
    "    print(f\"¡El PDF tiene {len(toc)} elementos en la tabla de contenidos!\")\n",
    "    print(\"\\nPrimeras 10 entradas:\")\n",
    "    for i, (level, title, page) in enumerate(toc[:100]):\n",
    "        indent = \"  \" * (level - 1)\n",
    "        print(f\"{indent}Nivel {level}: {title} (Página {page})\")\n",
    "else:\n",
    "    print(\"El PDF no tiene tabla de contenidos estructurada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc0d2a0",
   "metadata": {},
   "source": [
    "PREPROCESAR EL TEXTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfb064d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page</th>\n",
       "      <th>raw</th>\n",
       "      <th>normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>b'Online edition (c)\\n2009 Cambridge UP\\nAn\\nI...</td>\n",
       "      <td>bonline edition cn2009 cambridge upnannintrodu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>b'Online edition (c)\\n2009 Cambridge UP\\n'</td>\n",
       "      <td>bonline edition cn2009 cambridge upn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>b'Online edition (c)\\n2009 Cambridge UP\\nAn\\nI...</td>\n",
       "      <td>bonline edition cn2009 cambridge upnannintrodu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>b'Online edition (c)\\n2009 Cambridge UP\\nDRAFT...</td>\n",
       "      <td>bonline edition cn2009 cambridge upndraftndo n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>b'Online edition (c)\\n2009 Cambridge UP\\nDRAFT...</td>\n",
       "      <td>bonline edition cn2009 cambridge upndraft xc2x...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>577</td>\n",
       "      <td>b'Online edition (c)\\n2009 Cambridge UP\\n540\\n...</td>\n",
       "      <td>bonline edition cn2009 cambridge upn540nindexn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>578</td>\n",
       "      <td>b'Online edition (c)\\n2009 Cambridge UP\\nIndex...</td>\n",
       "      <td>bonline edition cn2009 cambridge upnindexn541n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>579</td>\n",
       "      <td>b'Online edition (c)\\n2009 Cambridge UP\\n542\\n...</td>\n",
       "      <td>bonline edition cn2009 cambridge upn542nindexn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>580</td>\n",
       "      <td>b'Online edition (c)\\n2009 Cambridge UP\\nIndex...</td>\n",
       "      <td>bonline edition cn2009 cambridge upnindexn543n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>581</td>\n",
       "      <td>b'Online edition (c)\\n2009 Cambridge UP\\n544\\n...</td>\n",
       "      <td>bonline edition cn2009 cambridge upn544nindexn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>581 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     page                                                raw  \\\n",
       "0       1  b'Online edition (c)\\n2009 Cambridge UP\\nAn\\nI...   \n",
       "1       2         b'Online edition (c)\\n2009 Cambridge UP\\n'   \n",
       "2       3  b'Online edition (c)\\n2009 Cambridge UP\\nAn\\nI...   \n",
       "3       4  b'Online edition (c)\\n2009 Cambridge UP\\nDRAFT...   \n",
       "4       5  b'Online edition (c)\\n2009 Cambridge UP\\nDRAFT...   \n",
       "..    ...                                                ...   \n",
       "576   577  b'Online edition (c)\\n2009 Cambridge UP\\n540\\n...   \n",
       "577   578  b'Online edition (c)\\n2009 Cambridge UP\\nIndex...   \n",
       "578   579  b'Online edition (c)\\n2009 Cambridge UP\\n542\\n...   \n",
       "579   580  b'Online edition (c)\\n2009 Cambridge UP\\nIndex...   \n",
       "580   581  b'Online edition (c)\\n2009 Cambridge UP\\n544\\n...   \n",
       "\n",
       "                                            normalized  \n",
       "0    bonline edition cn2009 cambridge upnannintrodu...  \n",
       "1                 bonline edition cn2009 cambridge upn  \n",
       "2    bonline edition cn2009 cambridge upnannintrodu...  \n",
       "3    bonline edition cn2009 cambridge upndraftndo n...  \n",
       "4    bonline edition cn2009 cambridge upndraft xc2x...  \n",
       "..                                                 ...  \n",
       "576  bonline edition cn2009 cambridge upn540nindexn...  \n",
       "577  bonline edition cn2009 cambridge upnindexn541n...  \n",
       "578  bonline edition cn2009 cambridge upn542nindexn...  \n",
       "579  bonline edition cn2009 cambridge upnindexn543n...  \n",
       "580  bonline edition cn2009 cambridge upn544nindexn...  \n",
       "\n",
       "[581 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preprocesar el texto\n",
    "import re\n",
    "#normalizar texto\n",
    "def normalize_text(text):\n",
    "    text = text.lower()  # Convertir a minúsculas\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Eliminar espacios en blanco extra\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Eliminar caracteres especiales\n",
    "    return text\n",
    "# Aplicar normalización al DataFrame\n",
    "df['normalized'] = df['raw'].apply(normalize_text)\n",
    "# Verificar el resultado\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0c2d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ELI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page</th>\n",
       "      <th>raw</th>\n",
       "      <th>normalized</th>\n",
       "      <th>filtered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>b'Online edition (c)\\n2009 Cambridge UP\\nAn\\nI...</td>\n",
       "      <td>bonline edition cn2009 cambridge upnannintrodu...</td>\n",
       "      <td>bonline edition cn2009 cambridge upnannintrodu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>b'Online edition (c)\\n2009 Cambridge UP\\n'</td>\n",
       "      <td>bonline edition cn2009 cambridge upn</td>\n",
       "      <td>bonline edition cn2009 cambridge upn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>b'Online edition (c)\\n2009 Cambridge UP\\nAn\\nI...</td>\n",
       "      <td>bonline edition cn2009 cambridge upnannintrodu...</td>\n",
       "      <td>bonline edition cn2009 cambridge upnannintrodu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>b'Online edition (c)\\n2009 Cambridge UP\\nDRAFT...</td>\n",
       "      <td>bonline edition cn2009 cambridge upndraftndo n...</td>\n",
       "      <td>bonline edition cn2009 cambridge upndraftndo d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>b'Online edition (c)\\n2009 Cambridge UP\\nDRAFT...</td>\n",
       "      <td>bonline edition cn2009 cambridge upndraft xc2x...</td>\n",
       "      <td>bonline edition cn2009 cambridge upndraft xc2x...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>577</td>\n",
       "      <td>b'Online edition (c)\\n2009 Cambridge UP\\n540\\n...</td>\n",
       "      <td>bonline edition cn2009 cambridge upn540nindexn...</td>\n",
       "      <td>bonline edition cn2009 cambridge upn540nindexn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>578</td>\n",
       "      <td>b'Online edition (c)\\n2009 Cambridge UP\\nIndex...</td>\n",
       "      <td>bonline edition cn2009 cambridge upnindexn541n...</td>\n",
       "      <td>bonline edition cn2009 cambridge upnindexn541n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>579</td>\n",
       "      <td>b'Online edition (c)\\n2009 Cambridge UP\\n542\\n...</td>\n",
       "      <td>bonline edition cn2009 cambridge upn542nindexn...</td>\n",
       "      <td>bonline edition cn2009 cambridge upn542nindexn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>580</td>\n",
       "      <td>b'Online edition (c)\\n2009 Cambridge UP\\nIndex...</td>\n",
       "      <td>bonline edition cn2009 cambridge upnindexn543n...</td>\n",
       "      <td>bonline edition cn2009 cambridge upnindexn543n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>581</td>\n",
       "      <td>b'Online edition (c)\\n2009 Cambridge UP\\n544\\n...</td>\n",
       "      <td>bonline edition cn2009 cambridge upn544nindexn...</td>\n",
       "      <td>bonline edition cn2009 cambridge upn544nindexn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>581 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     page                                                raw  \\\n",
       "0       1  b'Online edition (c)\\n2009 Cambridge UP\\nAn\\nI...   \n",
       "1       2         b'Online edition (c)\\n2009 Cambridge UP\\n'   \n",
       "2       3  b'Online edition (c)\\n2009 Cambridge UP\\nAn\\nI...   \n",
       "3       4  b'Online edition (c)\\n2009 Cambridge UP\\nDRAFT...   \n",
       "4       5  b'Online edition (c)\\n2009 Cambridge UP\\nDRAFT...   \n",
       "..    ...                                                ...   \n",
       "576   577  b'Online edition (c)\\n2009 Cambridge UP\\n540\\n...   \n",
       "577   578  b'Online edition (c)\\n2009 Cambridge UP\\nIndex...   \n",
       "578   579  b'Online edition (c)\\n2009 Cambridge UP\\n542\\n...   \n",
       "579   580  b'Online edition (c)\\n2009 Cambridge UP\\nIndex...   \n",
       "580   581  b'Online edition (c)\\n2009 Cambridge UP\\n544\\n...   \n",
       "\n",
       "                                            normalized  \\\n",
       "0    bonline edition cn2009 cambridge upnannintrodu...   \n",
       "1                 bonline edition cn2009 cambridge upn   \n",
       "2    bonline edition cn2009 cambridge upnannintrodu...   \n",
       "3    bonline edition cn2009 cambridge upndraftndo n...   \n",
       "4    bonline edition cn2009 cambridge upndraft xc2x...   \n",
       "..                                                 ...   \n",
       "576  bonline edition cn2009 cambridge upn540nindexn...   \n",
       "577  bonline edition cn2009 cambridge upnindexn541n...   \n",
       "578  bonline edition cn2009 cambridge upn542nindexn...   \n",
       "579  bonline edition cn2009 cambridge upnindexn543n...   \n",
       "580  bonline edition cn2009 cambridge upn544nindexn...   \n",
       "\n",
       "                                              filtered  \n",
       "0    bonline edition cn2009 cambridge upnannintrodu...  \n",
       "1                 bonline edition cn2009 cambridge upn  \n",
       "2    bonline edition cn2009 cambridge upnannintrodu...  \n",
       "3    bonline edition cn2009 cambridge upndraftndo d...  \n",
       "4    bonline edition cn2009 cambridge upndraft xc2x...  \n",
       "..                                                 ...  \n",
       "576  bonline edition cn2009 cambridge upn540nindexn...  \n",
       "577  bonline edition cn2009 cambridge upnindexn541n...  \n",
       "578  bonline edition cn2009 cambridge upn542nindexn...  \n",
       "579  bonline edition cn2009 cambridge upnindexn543n...  \n",
       "580  bonline edition cn2009 cambridge upn544nindexn...  \n",
       "\n",
       "[581 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#eliminar stopwords\n",
    "from nltk.corpus import stopwords\n",
    "# Definir stopwords en english\n",
    "stop_words = set(stopwords.words('english'))\n",
    "# Función para eliminar stopwords\n",
    "def remove_stopwords(text):\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "# Aplicar eliminación de stopwords al DataFrame\n",
    "df['filtered'] = df['normalized'].apply(remove_stopwords)\n",
    "# Verificar el resultado\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f942a6",
   "metadata": {},
   "source": [
    "EMBEDDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cdf29f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5946cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "#generar funcion embeddings para todo el texto\n",
    "def generate_embeddings(text):\n",
    "    return model.encode(text)\n",
    "# Aplicar la función de embeddings al DataFrame\n",
    "df['embeddings'] = df['filtered'].apply(generate_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4ff5eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page</th>\n",
       "      <th>raw</th>\n",
       "      <th>normalized</th>\n",
       "      <th>filtered</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>b'Online edition (c)\\n2009 Cambridge UP\\nAn\\nI...</td>\n",
       "      <td>bonline edition cn2009 cambridge upnannintrodu...</td>\n",
       "      <td>bonline edition cn2009 cambridge upnannintrodu...</td>\n",
       "      <td>[-0.11581327, -0.04094364, 0.023199067, -0.036...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>b'Online edition (c)\\n2009 Cambridge UP\\n'</td>\n",
       "      <td>bonline edition cn2009 cambridge upn</td>\n",
       "      <td>bonline edition cn2009 cambridge upn</td>\n",
       "      <td>[-0.1323803, -0.023347827, 0.06720841, -0.0928...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>b'Online edition (c)\\n2009 Cambridge UP\\nAn\\nI...</td>\n",
       "      <td>bonline edition cn2009 cambridge upnannintrodu...</td>\n",
       "      <td>bonline edition cn2009 cambridge upnannintrodu...</td>\n",
       "      <td>[0.00705546, -0.048072208, 0.007882582, -0.068...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>b'Online edition (c)\\n2009 Cambridge UP\\nDRAFT...</td>\n",
       "      <td>bonline edition cn2009 cambridge upndraftndo n...</td>\n",
       "      <td>bonline edition cn2009 cambridge upndraftndo d...</td>\n",
       "      <td>[-0.05006524, -0.0019235705, -0.016345194, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>b'Online edition (c)\\n2009 Cambridge UP\\nDRAFT...</td>\n",
       "      <td>bonline edition cn2009 cambridge upndraft xc2x...</td>\n",
       "      <td>bonline edition cn2009 cambridge upndraft xc2x...</td>\n",
       "      <td>[0.027868386, -0.087042965, -0.01009805, 0.016...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>577</td>\n",
       "      <td>b'Online edition (c)\\n2009 Cambridge UP\\n540\\n...</td>\n",
       "      <td>bonline edition cn2009 cambridge upn540nindexn...</td>\n",
       "      <td>bonline edition cn2009 cambridge upn540nindexn...</td>\n",
       "      <td>[-0.026038677, -0.12275319, -0.014319798, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>578</td>\n",
       "      <td>b'Online edition (c)\\n2009 Cambridge UP\\nIndex...</td>\n",
       "      <td>bonline edition cn2009 cambridge upnindexn541n...</td>\n",
       "      <td>bonline edition cn2009 cambridge upnindexn541n...</td>\n",
       "      <td>[0.02994777, -0.13199653, -0.008621623, -0.010...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>579</td>\n",
       "      <td>b'Online edition (c)\\n2009 Cambridge UP\\n542\\n...</td>\n",
       "      <td>bonline edition cn2009 cambridge upn542nindexn...</td>\n",
       "      <td>bonline edition cn2009 cambridge upn542nindexn...</td>\n",
       "      <td>[0.0034598007, -0.077709176, -0.0045174663, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>580</td>\n",
       "      <td>b'Online edition (c)\\n2009 Cambridge UP\\nIndex...</td>\n",
       "      <td>bonline edition cn2009 cambridge upnindexn543n...</td>\n",
       "      <td>bonline edition cn2009 cambridge upnindexn543n...</td>\n",
       "      <td>[-0.020311879, -0.13165753, 0.01688339, -0.020...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>581</td>\n",
       "      <td>b'Online edition (c)\\n2009 Cambridge UP\\n544\\n...</td>\n",
       "      <td>bonline edition cn2009 cambridge upn544nindexn...</td>\n",
       "      <td>bonline edition cn2009 cambridge upn544nindexn...</td>\n",
       "      <td>[0.009277609, -0.12823053, 0.015174442, 0.0130...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>581 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     page                                                raw  \\\n",
       "0       1  b'Online edition (c)\\n2009 Cambridge UP\\nAn\\nI...   \n",
       "1       2         b'Online edition (c)\\n2009 Cambridge UP\\n'   \n",
       "2       3  b'Online edition (c)\\n2009 Cambridge UP\\nAn\\nI...   \n",
       "3       4  b'Online edition (c)\\n2009 Cambridge UP\\nDRAFT...   \n",
       "4       5  b'Online edition (c)\\n2009 Cambridge UP\\nDRAFT...   \n",
       "..    ...                                                ...   \n",
       "576   577  b'Online edition (c)\\n2009 Cambridge UP\\n540\\n...   \n",
       "577   578  b'Online edition (c)\\n2009 Cambridge UP\\nIndex...   \n",
       "578   579  b'Online edition (c)\\n2009 Cambridge UP\\n542\\n...   \n",
       "579   580  b'Online edition (c)\\n2009 Cambridge UP\\nIndex...   \n",
       "580   581  b'Online edition (c)\\n2009 Cambridge UP\\n544\\n...   \n",
       "\n",
       "                                            normalized  \\\n",
       "0    bonline edition cn2009 cambridge upnannintrodu...   \n",
       "1                 bonline edition cn2009 cambridge upn   \n",
       "2    bonline edition cn2009 cambridge upnannintrodu...   \n",
       "3    bonline edition cn2009 cambridge upndraftndo n...   \n",
       "4    bonline edition cn2009 cambridge upndraft xc2x...   \n",
       "..                                                 ...   \n",
       "576  bonline edition cn2009 cambridge upn540nindexn...   \n",
       "577  bonline edition cn2009 cambridge upnindexn541n...   \n",
       "578  bonline edition cn2009 cambridge upn542nindexn...   \n",
       "579  bonline edition cn2009 cambridge upnindexn543n...   \n",
       "580  bonline edition cn2009 cambridge upn544nindexn...   \n",
       "\n",
       "                                              filtered  \\\n",
       "0    bonline edition cn2009 cambridge upnannintrodu...   \n",
       "1                 bonline edition cn2009 cambridge upn   \n",
       "2    bonline edition cn2009 cambridge upnannintrodu...   \n",
       "3    bonline edition cn2009 cambridge upndraftndo d...   \n",
       "4    bonline edition cn2009 cambridge upndraft xc2x...   \n",
       "..                                                 ...   \n",
       "576  bonline edition cn2009 cambridge upn540nindexn...   \n",
       "577  bonline edition cn2009 cambridge upnindexn541n...   \n",
       "578  bonline edition cn2009 cambridge upn542nindexn...   \n",
       "579  bonline edition cn2009 cambridge upnindexn543n...   \n",
       "580  bonline edition cn2009 cambridge upn544nindexn...   \n",
       "\n",
       "                                            embeddings  \n",
       "0    [-0.11581327, -0.04094364, 0.023199067, -0.036...  \n",
       "1    [-0.1323803, -0.023347827, 0.06720841, -0.0928...  \n",
       "2    [0.00705546, -0.048072208, 0.007882582, -0.068...  \n",
       "3    [-0.05006524, -0.0019235705, -0.016345194, -0....  \n",
       "4    [0.027868386, -0.087042965, -0.01009805, 0.016...  \n",
       "..                                                 ...  \n",
       "576  [-0.026038677, -0.12275319, -0.014319798, -0.0...  \n",
       "577  [0.02994777, -0.13199653, -0.008621623, -0.010...  \n",
       "578  [0.0034598007, -0.077709176, -0.0045174663, -0...  \n",
       "579  [-0.020311879, -0.13165753, 0.01688339, -0.020...  \n",
       "580  [0.009277609, -0.12823053, 0.015174442, 0.0130...  \n",
       "\n",
       "[581 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d39de64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.11581327, -0.04094364,  0.02319907, ..., -0.0260279 ,\n",
       "         0.02207126, -0.04298127],\n",
       "       [-0.1323803 , -0.02334783,  0.06720841, ...,  0.01590319,\n",
       "        -0.02216803,  0.01160852],\n",
       "       [ 0.00705546, -0.04807221,  0.00788258, ...,  0.0255634 ,\n",
       "        -0.02932286,  0.00203923],\n",
       "       ...,\n",
       "       [ 0.0034598 , -0.07770918, -0.00451747, ..., -0.01676263,\n",
       "        -0.03796598, -0.0576323 ],\n",
       "       [-0.02031188, -0.13165753,  0.01688339, ..., -0.06474322,\n",
       "        -0.04680839, -0.02762038],\n",
       "       [ 0.00927761, -0.12823053,  0.01517444, ..., -0.02842616,\n",
       "        -0.03841518, -0.03689068]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sacar los embeddings del df\n",
    "embeddings = np.array(df['embeddings'].tolist())\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a67575",
   "metadata": {},
   "source": [
    "QUERY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d5f55f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.49560859e-03,  1.38110016e-02,  3.26872654e-02, -3.50735500e-03,\n",
       "       -4.26756963e-03, -6.79441215e-03,  1.45399123e-01, -1.11046331e-02,\n",
       "       -7.86744952e-02,  2.04429794e-02,  6.93996670e-03, -2.10056063e-02,\n",
       "        4.66357656e-02, -4.85497192e-02, -7.59261772e-02,  8.11752751e-02,\n",
       "        4.30341251e-02,  4.64086644e-02, -9.42633674e-02, -9.08575580e-03,\n",
       "        6.45952672e-02,  1.34171650e-01,  2.02286150e-02,  2.76836660e-02,\n",
       "       -1.09036537e-02,  5.80462441e-02, -9.04709026e-02, -6.54042652e-03,\n",
       "        6.67781010e-02, -8.32427386e-03,  2.57875044e-02,  2.84907110e-02,\n",
       "        6.08631112e-02,  2.46394724e-02,  2.32363176e-02, -3.44091505e-02,\n",
       "       -1.05311200e-01,  5.39251119e-02,  2.46874914e-02, -1.99775379e-02,\n",
       "       -7.40725473e-02, -1.03850476e-01, -1.05458960e-01, -4.92498577e-02,\n",
       "        1.12935327e-01, -8.43069144e-03, -2.37405039e-02,  1.15957484e-02,\n",
       "        5.11254892e-02,  2.55397037e-02, -7.89895132e-02, -5.44321947e-02,\n",
       "       -2.77857948e-02,  4.07745168e-02,  5.46652041e-02, -4.98606823e-02,\n",
       "        5.50606027e-02, -6.10227510e-03,  1.57128684e-02, -3.19950171e-02,\n",
       "        5.04348166e-02, -6.95450418e-03, -1.12563029e-01,  1.59812476e-02,\n",
       "       -2.66369041e-02,  1.33425118e-02, -3.35357971e-02,  4.11395580e-02,\n",
       "        9.86386463e-03,  1.04485288e-01,  3.58191156e-03,  5.76096214e-02,\n",
       "        4.18155789e-02,  8.82757530e-02,  5.10127209e-02,  3.12808007e-02,\n",
       "        4.67001274e-02, -2.38265209e-02,  1.05396658e-01, -8.29283055e-03,\n",
       "       -3.11776735e-02, -5.82809336e-02,  3.25968042e-02, -3.96665670e-02,\n",
       "       -2.62721330e-02,  1.76127777e-02,  4.27872464e-02, -4.91569750e-02,\n",
       "        4.58962470e-02, -5.32164760e-02, -7.92004988e-02, -1.31060258e-01,\n",
       "        5.37770204e-02, -2.63286252e-02, -5.56075349e-02, -5.27327210e-02,\n",
       "       -1.01271033e-01, -5.77392019e-02,  3.00756749e-02,  1.52967855e-01,\n",
       "        4.36527766e-02,  1.37710124e-02, -2.15698145e-02, -4.30005528e-02,\n",
       "       -7.64405727e-02, -6.25144765e-02, -1.38545986e-02,  7.09717199e-02,\n",
       "       -5.38371783e-03, -1.46295847e-02, -7.02142417e-02,  1.53684169e-02,\n",
       "       -6.35770261e-02, -5.10385185e-02, -9.61093698e-03,  4.50118221e-02,\n",
       "        1.13295391e-02,  9.03673768e-02,  4.54282314e-02,  1.80453584e-02,\n",
       "        4.68757004e-03,  9.33001563e-02,  1.58547685e-02,  1.42760975e-02,\n",
       "       -5.64333349e-02, -7.01242536e-02,  3.12203579e-02, -3.39773887e-33,\n",
       "       -1.68736149e-02, -5.03039993e-02, -4.84312028e-02,  4.21389192e-02,\n",
       "        9.89233144e-03,  1.65894870e-02, -4.47337255e-02,  3.62527668e-02,\n",
       "        4.89242524e-02,  5.31930886e-02,  2.69234516e-02, -5.86375706e-02,\n",
       "        3.38096637e-03, -5.39196916e-02,  1.48222193e-01, -4.54560891e-02,\n",
       "        4.32491526e-02, -3.82457074e-04,  9.02365719e-04, -2.41772588e-02,\n",
       "        4.30193841e-02, -5.24586551e-02,  2.12449022e-02,  7.85362441e-04,\n",
       "       -5.80606163e-02, -3.14322896e-02, -6.52769804e-02, -6.14617541e-02,\n",
       "        3.39590311e-02,  6.48514926e-02, -1.97879039e-02, -3.96132544e-02,\n",
       "        5.66153154e-02,  5.45336269e-02,  1.37083381e-02, -3.03796716e-02,\n",
       "        5.51254628e-03, -5.84277548e-02, -1.02149397e-02, -1.17780507e-01,\n",
       "       -1.23385645e-01,  2.44554728e-02, -6.51074499e-02, -7.44798034e-03,\n",
       "        1.07660562e-01, -2.30963919e-02,  1.82456374e-02, -7.18064886e-03,\n",
       "        7.40239862e-03,  4.80398387e-02,  4.54193205e-02,  4.44028042e-02,\n",
       "       -4.42108735e-02,  5.61995320e-02, -1.80403907e-02,  2.04424057e-02,\n",
       "        1.68797262e-02,  2.19390634e-02, -5.13186231e-02, -4.54904474e-02,\n",
       "       -4.12525237e-02,  1.05924271e-02,  3.89571898e-02, -9.01019853e-03,\n",
       "       -4.05898839e-02, -3.11625618e-02, -2.60141622e-02,  3.40113863e-02,\n",
       "       -4.06838469e-02,  4.79287095e-02, -2.62019001e-02, -3.75996120e-02,\n",
       "        3.72779444e-02,  7.93791004e-03, -3.24457593e-04, -3.44919823e-02,\n",
       "        2.18065232e-02,  2.49705520e-02,  7.23750936e-03,  1.06472634e-02,\n",
       "        5.28212972e-02, -1.58585031e-02, -3.98166552e-02, -1.80337206e-02,\n",
       "       -2.72819940e-02, -4.59191613e-02,  2.86110509e-02, -1.03648216e-01,\n",
       "        4.14668992e-02,  6.31220043e-02, -1.31775707e-01,  8.09592828e-02,\n",
       "       -1.78688634e-02, -3.35996039e-02, -1.24460876e-01,  2.18873246e-33,\n",
       "       -6.25533238e-02, -3.27281170e-02, -3.70334946e-02,  2.62979176e-02,\n",
       "       -4.97802123e-02,  8.88015493e-04,  6.72134310e-02,  6.22418411e-02,\n",
       "        3.74592990e-02,  2.50373036e-02,  4.93161604e-02, -2.25159451e-02,\n",
       "        8.28313117e-04,  8.94823857e-03,  4.87676039e-02, -3.46517861e-02,\n",
       "        1.19102508e-01,  6.16159774e-02,  2.85450625e-03,  1.04769610e-01,\n",
       "       -6.72924221e-02, -2.75330823e-02, -8.85441452e-02, -2.21933667e-02,\n",
       "       -3.71344760e-02,  2.62090880e-02, -3.46328542e-02,  2.59234142e-02,\n",
       "       -2.57963547e-03,  2.61633433e-02,  9.08600166e-03,  5.81263043e-02,\n",
       "       -3.99809778e-02,  1.45678446e-02, -3.57088223e-02,  8.69376212e-03,\n",
       "       -3.24679017e-02,  2.67016552e-02, -6.45604506e-02,  7.78672099e-02,\n",
       "        5.25709875e-02,  2.37235148e-03, -5.19191958e-02,  3.72743644e-02,\n",
       "       -3.81415822e-02, -4.92513627e-02, -7.25615695e-02, -1.47923790e-02,\n",
       "        3.99299152e-02,  4.12567556e-02, -4.21517044e-02,  5.74369468e-02,\n",
       "       -4.30727052e-03, -1.79542322e-02,  1.10901771e-02, -7.65947774e-02,\n",
       "       -7.11048394e-02, -7.13938028e-02, -7.50903040e-02, -4.71375510e-02,\n",
       "        2.29640342e-02, -7.45739834e-03, -5.36899222e-03,  7.61548504e-02,\n",
       "        7.49299452e-02, -3.43900137e-02, -8.11513066e-02,  4.90519628e-02,\n",
       "        1.22714611e-02, -1.88819487e-02,  5.20869419e-02,  1.18928440e-02,\n",
       "       -8.58671889e-02, -2.94089108e-03, -9.28990617e-02, -6.82959799e-03,\n",
       "       -1.07445158e-01, -5.26459143e-02,  3.31977047e-02, -6.22288287e-02,\n",
       "        5.43723851e-02,  2.27718595e-02,  2.50977948e-02,  5.46200313e-02,\n",
       "       -4.57187705e-02, -1.77930854e-02, -7.16595277e-02, -7.34305149e-03,\n",
       "       -3.79458349e-03,  8.69043823e-03,  5.36074750e-02, -3.69317308e-02,\n",
       "        6.78913593e-02,  6.75247377e-03, -3.78016010e-02, -1.41637670e-08,\n",
       "       -5.67352101e-02, -4.07932419e-03,  7.57186487e-02,  7.59558007e-03,\n",
       "        4.98125814e-02, -3.34315300e-02,  1.13062793e-02,  6.92381188e-02,\n",
       "       -6.97447499e-03,  8.30163807e-03,  7.31794015e-02,  2.20696330e-02,\n",
       "       -1.57179553e-02,  9.77202505e-02,  2.31646816e-04, -9.94248223e-03,\n",
       "        5.39894141e-02,  9.65042971e-03,  1.12734390e-02, -4.04635854e-02,\n",
       "       -5.40181212e-02,  5.52954637e-02, -1.15938067e-01, -2.51252148e-02,\n",
       "        2.08169445e-02,  2.54807360e-02,  1.86110772e-02,  7.09262639e-02,\n",
       "        4.50047441e-02, -2.25867517e-02,  8.12138841e-02,  4.16815951e-02,\n",
       "       -9.02500972e-02, -4.54663336e-02, -3.52529483e-03,  6.87641203e-02,\n",
       "       -8.08570255e-03, -3.70551758e-02,  3.19098383e-02,  1.96891259e-02,\n",
       "        1.84312146e-02,  8.46597478e-02,  3.20015214e-02,  2.43468583e-02,\n",
       "        1.32686216e-02,  3.15156169e-02,  6.56160414e-02, -3.25499959e-02,\n",
       "        1.61910225e-02,  1.05654669e-03, -3.19140404e-03,  8.34278315e-02,\n",
       "        4.93808985e-02, -4.79649054e-03,  8.06483179e-02,  8.27923417e-03,\n",
       "        9.57589503e-03,  4.67768833e-02, -6.01301491e-02,  2.57616211e-02,\n",
       "        5.56659698e-02, -1.38345361e-02,  2.53715534e-02,  5.52726388e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#query\n",
    "query = \"stopwords\"\n",
    "query_embedding = model.encode(query)\n",
    "query_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c74b17",
   "metadata": {},
   "source": [
    "SIMILITUD COSENO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c9537090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.14673242,  0.08636067,  0.17792588,  0.12479579,  0.3501364 ,\n",
       "        0.08636067,  0.36092517,  0.3500868 ,  0.23611969,  0.3248849 ,\n",
       "        0.24582897,  0.22838886,  0.21565823,  0.08636067,  0.17770323,\n",
       "        0.2217893 ,  0.14515658,  0.08636067,  0.3878405 ,  0.3268564 ,\n",
       "        0.20410894,  0.21630645,  0.16421896,  0.09596944,  0.15224014,\n",
       "        0.08636067,  0.16589503,  0.20008476,  0.2729969 ,  0.14498296,\n",
       "        0.2922377 ,  0.29981863,  0.21870802,  0.2557671 ,  0.12749767,\n",
       "        0.16471665,  0.20196778,  0.31844175,  0.27793705,  0.3152651 ,\n",
       "        0.3540063 ,  0.34254867,  0.30332682,  0.29782933,  0.28053147,\n",
       "        0.2698514 ,  0.23350316,  0.2839531 ,  0.31669274,  0.26685682,\n",
       "        0.24922231,  0.32965595,  0.30776873,  0.3519211 ,  0.26064637,\n",
       "        0.38121098,  0.29442626,  0.25781736,  0.33245167,  0.29098356,\n",
       "        0.35760248,  0.3939588 ,  0.3240416 ,  0.5092842 ,  0.28471947,\n",
       "        0.2545432 ,  0.35800108,  0.2520738 ,  0.41189817,  0.42003295,\n",
       "        0.3808141 ,  0.37620786,  0.31803638,  0.2216465 ,  0.27283984,\n",
       "        0.3809304 ,  0.35954797,  0.28107068,  0.30224743,  0.31129313,\n",
       "        0.36597535,  0.22313313,  0.32497606,  0.32550725,  0.08636067,\n",
       "        0.4157646 ,  0.30484912,  0.21245848,  0.3329246 ,  0.2598113 ,\n",
       "        0.2819829 ,  0.34958097,  0.38803068,  0.3773619 ,  0.36418647,\n",
       "        0.17908159,  0.33549094,  0.31112987,  0.39010963,  0.26417884,\n",
       "        0.2930389 ,  0.27769595,  0.08636067,  0.17712715,  0.07406434,\n",
       "        0.16896333,  0.24542661,  0.17411275,  0.22374552,  0.2989425 ,\n",
       "        0.2741645 ,  0.17538376,  0.13444625,  0.25756854,  0.24319783,\n",
       "        0.1333884 ,  0.27897698,  0.25045308,  0.25577936,  0.26456484,\n",
       "        0.11373742,  0.23887096,  0.2397321 ,  0.33387437,  0.14906695,\n",
       "        0.33280903,  0.2127037 ,  0.2751383 ,  0.12930442,  0.17151824,\n",
       "        0.18857943,  0.26122785,  0.24984534,  0.19110797,  0.18527555,\n",
       "        0.09887913,  0.13068797,  0.1744573 ,  0.18585758,  0.2170731 ,\n",
       "        0.19511352,  0.2982963 ,  0.11439714,  0.2701391 ,  0.08636067,\n",
       "        0.23888148,  0.25350025,  0.15005441,  0.13929743,  0.13976774,\n",
       "        0.21420875,  0.11959624,  0.15006018,  0.26988938,  0.19721529,\n",
       "        0.28765985,  0.22745776,  0.17727305,  0.14862171,  0.19407624,\n",
       "        0.24727808,  0.18554609,  0.22704268,  0.18289676,  0.30383915,\n",
       "        0.25746408,  0.17937157,  0.2909736 ,  0.19169262,  0.27151147,\n",
       "        0.08636067,  0.26142552,  0.19877754,  0.24732304,  0.34134528,\n",
       "        0.14488775,  0.25115812,  0.20037776,  0.26432613,  0.228833  ,\n",
       "        0.23020367,  0.3018295 ,  0.20510499,  0.30159485,  0.30163163,\n",
       "        0.28481653,  0.15128437,  0.26901165,  0.2317846 ,  0.14515693,\n",
       "        0.28600043,  0.24585253,  0.2856608 ,  0.16339092,  0.18525779,\n",
       "        0.15427414,  0.19062145,  0.14231409,  0.11287825,  0.16770718,\n",
       "        0.27489594,  0.15421946,  0.13962276,  0.23181006,  0.20749125,\n",
       "        0.2738578 ,  0.18497866,  0.25361562,  0.21294746,  0.30339107,\n",
       "        0.22930005,  0.20973785,  0.08636067,  0.40985733,  0.26831353,\n",
       "        0.19759144,  0.14655955,  0.20977333,  0.17470872,  0.22182122,\n",
       "        0.31976044,  0.31351602,  0.29344222,  0.21471785,  0.28594416,\n",
       "        0.265009  ,  0.323458  ,  0.2907101 ,  0.40068808,  0.34920096,\n",
       "        0.35389045,  0.2177831 ,  0.2929634 ,  0.20909463,  0.15564932,\n",
       "        0.17133035,  0.20597577,  0.23788086,  0.19794069,  0.21925202,\n",
       "        0.26950228,  0.18592368,  0.2610351 ,  0.32479316,  0.12089644,\n",
       "        0.22380279,  0.2544128 ,  0.26699445,  0.24755949,  0.24161768,\n",
       "        0.21034336,  0.21647255,  0.1942562 ,  0.2564025 ,  0.26869944,\n",
       "        0.30805907,  0.08555797,  0.19577967,  0.13902014,  0.23254456,\n",
       "        0.14735   ,  0.21917547,  0.12602977,  0.20156947,  0.21171585,\n",
       "        0.0803232 ,  0.21036956,  0.23603429,  0.22591953,  0.18349877,\n",
       "        0.23936583,  0.1470418 ,  0.08636067,  0.26927236,  0.32630005,\n",
       "        0.42657512,  0.21356967,  0.2577073 ,  0.33914128,  0.16545844,\n",
       "        0.34579256,  0.22144157,  0.20848568,  0.29721183,  0.17395571,\n",
       "        0.22508875,  0.28186724,  0.2410442 ,  0.22989084,  0.23804346,\n",
       "        0.34147194,  0.20363693,  0.23355013,  0.26215032,  0.18396544,\n",
       "        0.09799913,  0.16290976,  0.22678985,  0.15139097,  0.16215572,\n",
       "        0.17655644,  0.14161375,  0.11829387,  0.12955499,  0.15443894,\n",
       "        0.26056615,  0.2525817 ,  0.24329433,  0.21180941,  0.16390443,\n",
       "        0.26181096,  0.17037691,  0.16371721,  0.23674206,  0.18278672,\n",
       "        0.25047773,  0.23408313,  0.15681323,  0.24499658,  0.20534933,\n",
       "        0.22641982,  0.19013888,  0.18997069,  0.22425786,  0.08636067,\n",
       "        0.24157865,  0.22877477,  0.07561812,  0.1397616 ,  0.13515736,\n",
       "        0.04635421,  0.11625525,  0.2700033 ,  0.16367424,  0.17018718,\n",
       "        0.1578218 ,  0.26046735,  0.19861348,  0.09127808,  0.14477527,\n",
       "        0.2927833 ,  0.1866794 ,  0.20440233,  0.14401191,  0.27458635,\n",
       "        0.23452298,  0.13585831,  0.21606341,  0.2572638 ,  0.24143845,\n",
       "        0.28700024,  0.15722634,  0.16723524,  0.13846138,  0.08636067,\n",
       "        0.2866949 ,  0.16144347,  0.22755253,  0.20001201,  0.10040982,\n",
       "        0.16343696,  0.12273093,  0.11958332,  0.24498609,  0.2132006 ,\n",
       "        0.2301264 ,  0.15151522,  0.14396116,  0.10397067,  0.11789223,\n",
       "        0.28700948,  0.29796028,  0.2186253 ,  0.20835963,  0.25520733,\n",
       "        0.37694022,  0.3385168 ,  0.32133162,  0.18032591,  0.16527413,\n",
       "        0.1863617 ,  0.18667983,  0.19963932,  0.26010495,  0.23592187,\n",
       "        0.22548175,  0.15291248,  0.23859718,  0.21456717,  0.23864608,\n",
       "        0.19691758,  0.21780159,  0.16350102,  0.08191293,  0.1686538 ,\n",
       "        0.15849826,  0.1201554 ,  0.25930294,  0.20569871,  0.07316237,\n",
       "        0.05371819,  0.19036618,  0.17714219,  0.11740717,  0.18900132,\n",
       "        0.1777215 ,  0.11464079,  0.2822524 ,  0.15397015,  0.22133784,\n",
       "        0.26417562,  0.21268839,  0.08636067,  0.13567595,  0.12937249,\n",
       "        0.20151895,  0.11999527,  0.12483323,  0.14083922,  0.23761357,\n",
       "        0.11065327,  0.08301096,  0.09521721,  0.10889447,  0.12459656,\n",
       "        0.10311458,  0.07246315,  0.08477129,  0.02328806,  0.07822014,\n",
       "        0.11915442,  0.17103265,  0.13885024,  0.3329748 ,  0.23127712,\n",
       "        0.0938229 ,  0.20277566,  0.1205794 ,  0.08636067,  0.25311068,\n",
       "        0.11195547,  0.05773176,  0.09785221,  0.07907808,  0.07850754,\n",
       "        0.06792559,  0.221981  ,  0.03295448,  0.14836158,  0.28666002,\n",
       "        0.27061966,  0.13389386,  0.2176181 ,  0.16358231,  0.19733687,\n",
       "       -0.01104905,  0.08636067,  0.28530994,  0.1652957 ,  0.31055287,\n",
       "        0.33458486,  0.22981139,  0.19386429,  0.38912907,  0.39281908,\n",
       "        0.39881378,  0.24801572,  0.33632213,  0.4210408 ,  0.3106561 ,\n",
       "        0.24087727,  0.12978072,  0.23810668,  0.2902874 ,  0.2561162 ,\n",
       "        0.07695567,  0.07117411,  0.21257731,  0.25427827,  0.24490649,\n",
       "        0.18784936,  0.17853074,  0.21893051,  0.24021257,  0.2037487 ,\n",
       "        0.21720576,  0.18235596,  0.20228304,  0.19593963,  0.19563736,\n",
       "        0.16932985,  0.21836248,  0.295004  ,  0.20819485,  0.25423858,\n",
       "        0.066998  ,  0.08636067,  0.2624466 ,  0.2391956 ,  0.40854257,\n",
       "        0.17598253,  0.15648635,  0.06506277,  0.16964315,  0.11022314,\n",
       "        0.05911681,  0.19905272,  0.20900567,  0.20622371,  0.08862299,\n",
       "        0.19841911,  0.28814733,  0.1073504 ,  0.2541265 ,  0.27679294,\n",
       "        0.3156104 ,  0.04975419,  0.23449625,  0.08636067,  0.30620545,\n",
       "        0.2943634 ,  0.2298884 ,  0.3505874 ,  0.25410593,  0.2535547 ,\n",
       "        0.20560876,  0.38227677,  0.21479356,  0.20313205,  0.26930532,\n",
       "        0.32519704,  0.2339057 ,  0.22902323,  0.30526242,  0.3525627 ,\n",
       "        0.34277207,  0.3218965 ,  0.2744781 ,  0.22360304,  0.33975306,\n",
       "        0.23819396,  0.31358263,  0.3491647 ,  0.2924698 ,  0.25029832,\n",
       "        0.28029323,  0.2663223 ,  0.36781296,  0.32788658,  0.29888356,\n",
       "        0.18026158,  0.2280104 ,  0.21853943,  0.3152548 ,  0.2820226 ,\n",
       "        0.2852575 ,  0.27716663,  0.24347684,  0.22415422,  0.1619408 ,\n",
       "        0.18181285,  0.21335718,  0.21549633,  0.18458268,  0.22524795,\n",
       "        0.24805783,  0.23262511,  0.17537254,  0.26996794,  0.2530791 ,\n",
       "        0.22548671,  0.27068833,  0.08636067,  0.30013603,  0.2674075 ,\n",
       "        0.2832198 ,  0.3146376 ,  0.21677949,  0.18064567,  0.25974932,\n",
       "        0.26785782], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#similitud coseno de la consulta hecho embedding con los embeddings\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarity_scores = cosine_similarity([query_embedding], embeddings)[0]\n",
    "#mostrar los resultados\n",
    "similarity_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b2577217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 63, 275, 468,  69,  85], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtener los índices de las 5 entradas más similares\n",
    "top_k_indices = np.argsort(similarity_scores)[-5:][::-1]\n",
    "top_k_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ed5114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados más similares:\n",
      "Página 64: bonline edition cn2009 cambridge upn22ndetermining vocabulary termsn27n222ndropping common terms stop wordsnsometimes extremely common words would appear ofnlittle value helping select documents match...\n",
      "Similitud: 0.5093\n",
      "\n",
      "Página 276: bonline edition cn2009 cambridge upn121nlanguage modelsn239nmodel m1nmodel m2nthen02nthen015nan01nan012nfrogn001nfrogn00002ntoadn001ntoadn00001nsaidn003nsaidn003nlikesn002nlikesn004nthatn004nthatn004n...\n",
      "Similitud: 0.4266\n",
      "\n",
      "Página 469: bonline edition cn2009 cambridge upn432n19nweb search basicsn194nthe search user experiencenit crucial understand users web search well isnagain signixefxacx81cant change traditional information retri...\n",
      "Similitud: 0.4210\n",
      "\n",
      "Página 70: bonline edition cn2009 cambridge upn22ndetermining vocabulary termsn33nlinguistic processing stemming lemmatization often done adnditional plugin component indexing process number suchncomponents exis...\n",
      "Similitud: 0.4200\n",
      "\n",
      "Página 86: bonline edition cn2009 cambridge upndraft xc2xa9 april 1 2009 cambridge university press feedback welcomen49n3ndictionaries tolerantnretrievalnin chapters 1 2 developed ideas underlying inverted index...\n",
      "Similitud: 0.4158\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#imprimir los 5 resultados más similares de cuando ya esta preprocesado\n",
    "print(\"Resultados más similares:\")\n",
    "for index in top_k_indices:\n",
    "    print(f\"Página {df.iloc[index]['page']}: {df.iloc[index]['filtered'][:200]}...\")  \n",
    "    print(f\"Similitud: {similarity_scores[index]:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "61448ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contexto de los resultados más similares:\n",
      "bonline edition cn2009 cambridge upn22ndetermining vocabulary termsn27n222ndropping common terms stop wordsnsometimes extremely common words would appear ofnlittle value helping select documents matching user need excludednfrom vocabulary entirely words called stop words generalnstop wordsnstrategy determining stop list sort terms collection frequencyncollectionnfrequencynthe total number times term appears document collectionnand take frequent terms often handxefxacx81ltered senmantic content relative domain documents indexed asna stop list members discarded indexing annstop listnexample stop list shown figure 25 using stop list signixefxacx81cantlynreduces number postings system store presentnsome statistics chapter 5 see table 51 page 87 lot ofnthe time indexing stop words little harm keyword searches withnterms like donxe2x80x99t seem useful however true fornphrase searches phrase query xe2x80x9cpresident united statesxe2x80x9d conntains two stop words precise president xe2x80x9cunited statesxe2x80x9d thenmeaning xefxacx82ights london likely lost word stopped ansearch vannevar bushxe2x80x99s article may think difxefxacx81cult xefxacx81rstnthree words stopped system searches simply documentsncontaining word think special query types disproportionatelynaffected song titles well known pieces verse consist entirely ofnwords commonly stop lists let donxe2x80x99t wantnto nthe general trend ir systems time standard use ofnquite large stop lists 200xe2x80x93300 terms small stop lists 7xe2x80x9312 termsnto stop list whatsoever web search engines generally use stopnlists design modern ir systems focused precisely onnhow exploit statistics language able cope withncommon words better ways show section 53 page 95 howngood compression techniques greatly reduce cost storing postingsnfor common words section 621 page 117 discusses standardnterm weighting leads common words little impact docnument rankings finally section 715 page 140 shows ir systemnwith impactsorted indexes terminate scanning postings list early whennweights get small hence common words cause large additionalnprocessing cost average query even though postings lists stopnwords long modern ir systems additional cost ofnincluding stop words big xe2x80x93 neither terms index size innterms query processing timen bonline edition cn2009 cambridge upn121nlanguage modelsn239nmodel m1nmodel m2nthen02nthen015nan01nan012nfrogn001nfrogn00002ntoadn001ntoadn00001nsaidn003nsaidn003nlikesn002nlikesn004nthatn004nthatn004ndogn0005ndogn001ncatn0003ncatn0015nmonkeyn0001nmonkeyn0002nnnnnxe2x97xaefigure 123npartial specixefxacx81cation two unigram language modelsnx0fnexample 121nto xefxacx81nd probability word sequence multiply thenprobabilities model gives word sequence together thenprobability continuing stopping producing word examplenpfrog said toad likes frognn001 xc3x97 003 xc3x97 004 xc3x97 001 xc3x97 002 xc3x97 001n122nxc3x9708 xc3x97 08 xc3x97 08 xc3x97 08 xc3x97 08 xc3x97 08 xc3x97 02nxe2x89x88n0000000000001573nas see probability particular stringdocument usually verynsmall number stopped generating frog second time xefxacx81rst line ofnnumbers term emission probabilities second line gives probabilnity continuing stopping generating word explicit stop probabilitynis needed xefxacx81nite automaton wellformed language model according tonequation 121 nevertheless time omit include stop andn1 xe2x88x92stop probabilities authors compare two models andata set calculate likelihood ratio results simply dividing thenlikelihood rationprobability data according one model probability data accordning model providing stop probability xefxacx81xed inclusion willnnot alter likelihood ratio results comparing likelihood two lannguage models generating string hence alter ranking documents2nnevertheless formally numbers longer truly probabilities onlynproportional probabilities see exercise 124nx0fnexample 122nsuppose two language models m1 m2nshown partially figure 123 gives probability estimate sequence ofn2 ir context leading taking stop probability xefxacx81xed acrossnmodels seems reasonable generating queries length distributionnof queries xefxacx81xed independent document generating languagenmodeln bonline edition cn2009 cambridge upn432n19nweb search basicsn194nthe search user experiencenit crucial understand users web search well isnagain signixefxacx81cant change traditional information retrieval usersnwere typically professionals least training art phrasingnqueries wellauthored collection whose style structure unnderstood well contrast web search users tend know care aboutnthe heterogeneity web content syntax query languages artnof phrasing queries indeed mainstream tool web search come tonbecome place onerous demands billions people anrange studies concluded average number keywords anweb search somewhere 2 3 syntax operators boolean connnectives wildcards etc seldom used result compositionnof audience xe2x80x93 xe2x80x9cnormalxe2x80x9d people information scientistsnit clear user trafxefxacx81c web search engine attract thenmore revenue stands earn sponsored search search enngines differentiate grow trafxefxacx81c google identixefxacx81edntwo principles helped grow expense competitors 1 anfocus relevance specixefxacx81cally precision rather recall xefxacx81rst rensults 2 user experience lightweight meaning searchnquery page search results page uncluttered almost entirelyntextual graphical elements effect xefxacx81rst simplynto save users time locating information sought effect thensecond provide user experience extremely responsive anynrate bottlenecked time load search query results pagen1941nuser query needsnthere appear three broad categories common web searchnqueries grouped informational ii navigational iii transacntional explain categories clear queriesnwill fall one categories others fall outsidenthemninformational queries seek general information broad topic asninformationalnqueriesnleukemia provence typically single web page conntains information sought indeed users informational queriesntypically try assimilate information multiple web pagesnnavigational queries seek website home page single entity thennavigationalnqueriesnuser mind say lufthansa airlines cases userxe2x80x99s expectationnis xefxacx81rst search result home page lufthansanthe user interested plethora documents containing termnlufthansa user best measure user satisfaction precision atn1n bonline edition cn2009 cambridge upn22ndetermining vocabulary termsn33nlinguistic processing stemming lemmatization often done adnditional plugin component indexing process number suchncomponents exist commercial opensourcenthe common algorithm stemming english one renpeatedly shown empirically effective porterxe2x80x99s algorithmnporter stemmernporter 1980 entire algorithm long intricate present herenbut indicate general nature porterxe2x80x99s algorithm consists 5 phasesnof word reductions applied sequentially within phase varnious conventions select rules selecting rule rulengroup applies longest sufxefxacx81x xefxacx81rst phase convention isnused following rule groupn21nrulenexamplenssesnxe2x86x92nssncaressesnxe2x86x92ncaressniesnxe2x86x92ninponiesnxe2x86x92nponinssnxe2x86x92nssncaressnxe2x86x92ncaressnsnxe2x86x92ncatsnxe2x86x92ncatnmany later rules use concept measure word looselynchecks number syllables see whether word long enough itnis reasonable regard matching portion rule sufxefxacx81x rather thannas part stem word example rulenm 1nementnxe2x86x92nwould map replacement replac cement c ofxefxacx81cial site thenporter stemmer isnhttpwwwtartarusorgxcbx9cmartinporterstemmernother stemmers exist including older onepass lovins stemmer lovinsn1968 newer entrants like paicehusk stemmer paice 1990 seenhttpwwwcswaikatoacnzxcbx9ceibestemmersnhttpwwwcomplancsacukcomputingresearchstemmingnfigure 28 presents informal comparison different behaviors thesenstemmers stemmers use languagespecixefxacx81c rules require less knownledge lemmatizer needs complete vocabulary morphonlogical analysis correctly lemmatize words particular domains may alsonrequire special stemming rules however exact stemmed form notnmatter equivalence classes formsnrather using stemmer use lemmatizer tool natnlemmatizernural language processing full morphological analysis accunrately identify lemma word full morphological analysisnproduces modest benexefxacx81ts retrieval hard say moren bonline edition cn2009 cambridge upndraft xc2xa9 april 1 2009 cambridge university press feedback welcomen49n3ndictionaries tolerantnretrievalnin chapters 1 2 developed ideas underlying inverted indexesnfor handling boolean proximity queries develop techniquesnthat robust typographical errors query well alternativenspellingsnin section 31 develop data structures help searchnfor terms vocabulary inverted index section 32 studynthe idea wildcard query query aeiou seeks docnwildcard querynuments containing term includes xefxacx81ve vowels sequencenthe symbol indicates possibly empty string characters users posensuch queries search engine uncertain spellna query term seek documents containing variants query term innstance query automat would seek documents containing termsnautomatic automation automatednwe turn forms imprecisely posed queries focusing onnspelling errors section 33 users make spelling errors either accidentnor term searching eg herman unambiguousnspelling collection detail number techniques correctingnspelling errors queries one term time well entire stringnof query terms finally section 34 study method seeking voncabulary terms phonetically close query terms benespecially useful cases like herman example user may notnknow proper name spelled documents collectionnbecause develop many variants inverted indexes chapternwe use sometimes phrase standard inverted index mean invertednindex developed chapters 1 2 vocabulary term anpostings list documents collectionn31nsearch structures dictionariesngiven inverted index query xefxacx81rst task determine whetherneach query term exists vocabulary identify pointer\n"
     ]
    }
   ],
   "source": [
    "#unir los 5 resultados más similares\n",
    "context = \" \".join(df.iloc[index]['filtered'] for index in top_k_indices)\n",
    "# Imprimir el contexto\n",
    "print(\"Contexto de los resultados más similares:\")\n",
    "print(context)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3e33b3",
   "metadata": {},
   "source": [
    "INTEGRACIÓN CON IA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d4192ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"Eres una aplicación de Retrieval Augmented Generation que siempre responde en español. Usa el siguiente contexto para responder la pregunta.\n",
    "Si la respuesta no está en el contexto, di que no sabes.\n",
    "\n",
    "Contexto:\n",
    "{context}\n",
    "\n",
    "Pregunta:\n",
    "El usuario está preguntando sobre: {query}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "83ff1ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4073518b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AQUI API KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cd079e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las \"stop words\" o \"stopwords\" son palabras extremadamente comunes en un idioma que tienen poco valor a la hora de ayudar a seleccionar documentos que coincidan con la necesidad del usuario. Estas palabras suelen excluirse del vocabulario durante el proceso de indexación. Por ejemplo, términos como \"y\", \"de\" o \"el\" se consideran stop words y no se utilizan para evaluar la relevancia de los documentos porque aparecen con tanta frecuencia que no aportan información útil.\n",
      "\n",
      "El uso de listas de stop words es una estrategia para reducir el tamaño de los índices en los sistemas de recuperación de información (IR), ya que permite descartar palabras que no contribuyen a la búsqueda. Sin embargo, el uso de stop words puede afectar a ciertos tipos de consultas, como las búsquedas en frases, donde incluso las palabras comunes pueden ser relevantes.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
